# Ilograph MCP Server: Technical Architecture & Implementation

The Ilograph MCP Server is a comprehensive FastMCP-based server implementation providing AI agents with real-time access to Ilograph documentation, diagram validation capabilities, and architectural guidance. Built as a Model Context Protocol (MCP) server, it serves as an intelligent intermediary between AI models and Ilograph's ecosystem, enabling automated diagram creation, validation, and architecture documentation workflows. The project demonstrates advanced Python development practices, async/await patterns, service architecture design, performance engineering, and DevOps containerization strategies.

## Background: Model Context Protocol

The Model Context Protocol (MCP) is an open standard developed by Anthropic that enables AI models to securely access external data sources, tools, and services. MCP creates a standardized interface between AI applications and external systems using JSON-RPC communication protocol, similar to how USB-C provides universal connectivity for hardware devices. MCP servers are background processes that expose specific capabilities including tools (executable functions AI models invoke), resources (static or dynamic data AI models read), and prompts (reusable interaction templates). The protocol enables standardization through a single interface for connecting AI models to external systems, security through controlled access with authentication and authorization, composability allowing multiple MCP servers connected to a single AI client, and extensibility for adding new capabilities without modifying core AI systems. The architecture follows a pattern where AI clients communicate with MCP servers via JSON-RPC protocol, which then interface with external APIs and data sources.

## Project Overview

The Ilograph MCP Server addresses the critical gap between AI models and architectural diagram creation by providing real-time documentation access to Ilograph's comprehensive documentation, intelligent YAML and schema validation with contextual error messages, example-driven learning through curated diagram examples with detailed explanations, icon discovery via semantic search through Ilograph's extensive icon catalog, and best practice guidance including architecture patterns and optimization recommendations. Primary users include software architects creating and validating complex system diagrams, DevOps engineers documenting infrastructure and deployment architectures, technical writers generating architectural documentation, and development teams maintaining living documentation of system designs. Secondary users include AI developers building Ilograph-aware AI assistants, documentation teams automating diagram creation workflows, and compliance teams ensuring architectural documentation standards.

Traditional architectural diagramming involves manual creation with steep learning curves, inconsistent documentation practices, difficulty maintaining diagram-code synchronization, limited validation and error checking, and time-intensive diagram creation processes. The Ilograph MCP Server transforms this landscape by enabling natural language to diagram generation, real-time validation and error correction, automated best practice enforcement, and live documentation that stays current. The system provides acceleration by reducing diagram creation time from hours to minutes, accuracy through real-time validation preventing syntax and structural errors, consistency by enforcing organizational standards through AI guidance, learning acceleration through built-in tutorials and examples, and seamless integration with AI development workflows.

## Technical Architecture

The server implements a layered architecture optimizing for performance, maintainability, and extensibility. The architecture consists of MCP client layer supporting Cursor, Claude Desktop, VS Code and other clients via JSON-RPC over stdio/HTTP, FastMCP server core handling tool registration and protocol management, tool orchestration layer containing documentation tools, validation engine, and example access tools, core services layer including content fetcher with HTTP and retry logic, TTL multi-tier cache system, and content parser for HTML to Markdown conversion, and external data sources layer interfacing with live Ilograph documentation, icon catalog APIs, and embedded static examples.

The core technology stack utilizes FastMCP 2.7.0+ as the primary framework providing modern async/await architecture, decorator-based tool registration, built-in JSON-RPC protocol handling, and type-safe request/response validation. The HTTP client stack combines httpx with asyncio for connection pooling ensuring efficient resource usage, exponential backoff retry logic, comprehensive error handling, and request/response logging and monitoring. Content processing leverages BeautifulSoup4 and lxml for robust HTML parsing with fallback parsers, intelligent content extraction algorithms, link resolution and URL normalization, and clean markdown generation optimized for LLM consumption. The validation engine combines PyYAML with custom schema implementation providing multi-stage validation pipeline, YAML syntax validation, Ilograph schema compliance checking, and contextual error messages with suggestions. The caching system implements custom TTL-based memory cache with multi-tier caching strategy, automatic expiration and cleanup, memory usage monitoring, and cache statistics and health metrics.

The project structure follows a modular organization with src/ilograph_mcp containing server.py for FastMCP server initialization and tool registration, core directory with fetcher.py implementing content fetching with retry logic and caching, cache.py providing TTL-based in-memory caching implementation, tools directory containing register_fetch_documentation_tools.py for documentation access tools, register_validate_diagram_tool.py for validation and error checking, register_example_tools.py for example diagram access, register_fetch_spec_tool.py for specification fetching, register_fetch_icons_tool.py for icon catalog search, utils directory with http_client.py implementing HTTP client with connection pooling, markdown_converter.py providing HTML to Markdown conversion engine, and static directory containing examples subdirectory with curated example diagrams including serverless-on-aws.ilograph (1922 lines, advanced serverless architecture), aws-distributed-load-testing.ilograph (887 lines, load testing infrastructure), and stack-overflow-architecture-2016.ilograph (958 lines, complex web architecture).

## Implementation Details

The FastMCP server implementation leverages decorator-based architecture for clean, maintainable tool registration through create_server function returning FastMCP instance named "Ilograph Context Server" with comprehensive instructions describing diagram creation and validation capabilities. The server registers multiple tools including fetch_documentation_tool, validate_diagram_tool, example_tools, fetch_spec_tool, and fetch_icons_tool. Key implementation features include type safety through Pydantic models for all request/response validation, async architecture with full async/await support for I/O operations, context integration providing built-in logging, progress reporting, and error handling, and metadata-rich tool annotations for discoverability.

The IlographContentFetcher class implements sophisticated content retrieval system integrating HTTP client, markdown converter, and cache components with cache TTL configuration setting documentation to 86400 seconds (24 hours), specification to 86400 seconds, and icons to 86400 seconds. Advanced features include intelligent caching strategy with documentation using 24-hour TTL for stability, specifications using 24-hour TTL with invalidation triggers, and icons using 24-hour TTL with semantic search indexing. Error recovery mechanisms implement circuit breaker pattern for external API failures, graceful degradation with cached fallbacks, and comprehensive error logging and monitoring. The content processing pipeline performs HTML sanitization and content extraction, link resolution and URL normalization, and markdown optimization specifically designed for LLM consumption.

The IlographHTTPClient implements enterprise-grade networking with resilience patterns using timeout of 30 seconds and max_retries of 3, configured with browser-like headers including User-Agent "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36", Accept "text/html,application/xhtml+xml,application/xml;q=0.9", Accept-Encoding "gzip, deflate", and Connection "keep-alive" for compatibility. Networking features include connection pooling for reused connections ensuring efficiency, exponential backoff implementing smart retry logic for transient failures, request/response logging providing comprehensive debugging capabilities, and error classification with differentiated handling for client versus server errors.

The IlographValidator implements multi-stage validation pipeline for comprehensive error detection through validate method returning ValidationResult after processing three sequential stages. Stage 1 performs YAML Syntax Validation using PyYAML parsing with detailed error reporting, line/column error positioning, and syntax suggestion generation, terminating early if YAML is invalid. Stage 2 conducts Schema Structure Validation including top-level property validation, resource hierarchy checking, perspective structure validation, and reference integrity checking. Stage 3 executes Semantic Validation enforcing business rules, providing best practice recommendations, and generating performance optimization suggestions. The validation system maintains known property sets including known_top_level_properties (resources, perspectives, contexts, imports, layout), known_resource_properties (id, name, subtitle, description, icon, iconStyle, color, children, instanceOf, abstract, alias, for), known_perspective_properties (name, description, notes, extends, aliases, overrides, relations, sequences), and known_relation_properties (from, to, via, label, description, color, arrowDirection, secondary).

The MemoryCache implements sophisticated TTL-based caching strategy using _cache dictionary storing CacheEntry objects with automatic expiration checking in get method that returns None for missing keys, deletes expired entries, and returns entry.data for valid entries. CacheEntry objects store data with created_at timestamp and expires_at calculated from TTL seconds, providing is_expired method checking current time against expires_at and age_seconds method calculating entry age. Cache features include TTL management with automatic expiration and configurable timeouts, memory monitoring implementing size-based eviction policies, statistics tracking providing performance metrics and hit/miss ratios through stats method returning total_entries, valid_entries, expired_entries, and keys list, and health monitoring offering cache health reporting for diagnostics including cleanup_expired method removing expired entries and returning count of removed items.

## Tool Ecosystem

The documentation tools include fetch_documentation_tool retrieving live Ilograph documentation sections using section parameter (string) for documentation section identifier, outputting markdown-formatted documentation content with 24-hour TTL caching and intelligent invalidation, implementing graceful degradation with cached fallbacks for error handling. The list_documentation_sections tool enumerates available documentation sections requiring no parameters, outputting structured list with descriptions and coverage areas, achieving sub-100ms response time through always-cached performance. The check_documentation_health tool provides service health monitoring and diagnostics requiring no parameters, outputting health status with cache statistics and connectivity metrics, designed for monitoring and debugging tool connectivity issues. Supported documentation sections include resources (resource tree organization, hierarchies, instanceOf patterns), relation-perspectives (arrow connections, from/to properties, routing, labels), sequence-perspectives (time-based diagrams with steps, bidirectional flows), references (resource reference patterns and advanced referencing), advanced-references (complex reference scenarios and usage patterns), resource-sizes-and-positions (layout control, resource sizing, visual hierarchy), parent-overrides (resource parent overrides in perspectives with scale properties), perspectives-other-properties (additional perspective properties and options), icons (icon system with iconStyle, icon paths, categorization), walkthroughs (interactive step-by-step guides), contexts (multiple context views with roots, extends inheritance), imports (namespace management with from/namespace properties, component reuse), markdown (rich text support in descriptions, notes, diagram text), and tutorial (complete tutorial for learning Ilograph diagram creation).

The specification tools include fetch_spec_tool retrieving official Ilograph specification requiring no parameters, outputting complete specification with property definitions and types in structured markdown format with searchable property tables, utilizing 24-hour TTL caching with manual refresh capability. The check_spec_health tool provides specification service health monitoring requiring no parameters and outputting connectivity status and cache health metrics.

The example tools include list_examples listing available diagram examples by complexity using optional category parameter filtering by beginner/intermediate/advanced levels, outputting categorized example list with learning objectives, achieving instant response through static content. The fetch_example tool retrieves specific example diagrams with context using example_name parameter (string) for filename of desired example, outputting complete diagram with metadata and learning notes. Available examples include serverless-on-aws.ilograph (1922 lines, advanced complexity demonstrating serverless architecture patterns), aws-distributed-load-testing.ilograph (887 lines, intermediate complexity showing load testing infrastructure), and stack-overflow-architecture-2016.ilograph (958 lines, intermediate complexity illustrating complex web architecture).

The validation tools include validate_diagram_tool providing comprehensive diagram validation with error reporting using content parameter (string) for Ilograph diagram YAML content, outputting detailed validation results with suggestions through multi-stage validation pipeline, line-specific error reporting, contextual suggestions and fixes, and performance optimization recommendations. The get_validation_help tool provides validation guidance and troubleshooting requiring no parameters, outputting comprehensive help documentation containing common errors, syntax patterns, and best practices.

The icon tools include search_icons_tool providing semantic search through Ilograph's icon catalog using query parameter (string) for search terms like 'database' or 'aws lambda' and optional provider parameter filtering by AWS, Azure, GCP providers, outputting ranked list of matching icons with usage examples through semantic matching algorithm, provider-based filtering, usage example generation, and relevance scoring. The list_icon_providers_tool enumerates available icon providers and categories requiring no parameters, outputting hierarchical provider structure with icon counts, utilizing cached performance with live statistics. The icon search implements scoring algorithm assigning 100 points for exact name matches, 50 points for category matches, 25 points for provider matches, 10 points for path matches, and 5 points for general text matches, returning top 50 results sorted by relevance score.

## Performance & Scalability

The performance characteristics include response time targets of documentation fetching under 500ms (cached) and under 2 seconds (fresh), example access under 100ms (always cached), validation operations under 300ms for typical diagrams, health checks under 200ms, and list operations under 100ms. Throughput capacity supports 50+ simultaneous concurrent requests, maintains cache hit ratio greater than 90% for documentation access, utilizes memory usage under 200MB baseline and under 500MB under load, and maintains HTTP connection pool of 20 persistent connections.

The caching strategy implements multi-tier architecture with L1 Memory layer for hot data using TTL of 1-24 hours, L2 Disk layer for persistent storage using TTL of 7 days, and L3 External layer for live source data. Cache policies include hot documentation with 24-hour TTL and high-priority retention, specifications with 24-hour TTL and manual invalidation capability, icon catalog with 24-hour TTL and incremental updates, and examples with permanent cache for static content.

Scalability considerations include horizontal scaling through stateless design enabling load balancing, shared cache layer for multi-instance deployments, and database-backed caching for persistence. Vertical scaling utilizes memory-efficient data structures, streaming processing for large documents, and lazy loading for infrequently accessed content. Network optimization implements HTTP/2 support for multiplexed connections, compression for large document transfers, and CDN integration for static content delivery.

## Development & Deployment

The development environment utilizes Python 3.11+ providing type hints and async improvements, UV package manager for fast dependency resolution, and virtual environment isolation. Key dependencies include fastmcp>=2.7.0 as MCP server framework, pyyaml>=6.0.0 for YAML processing, httpx>=0.25.0 as async HTTP client, beautifulsoup4>=4.12.0 for HTML parsing, lxml>=4.9.0 for XML/HTML processing, and pydantic>=2.0.0 for data validation. Development tools include pytest with async support achieving 95%+ coverage for testing, black, isort, and mypy for code quality linting, bandit for security vulnerability scanning, and mypy with strict configuration for type checking.

The containerization strategy implements multi-stage Docker build with Stage 1 performing dependency installation using python:3.12-slim base image, copying UV package manager from ghcr.io/astral-sh/uv:latest, copying pyproject.toml and uv.lock files, running uv sync --locked --no-install-project for dependency installation, and Stage 2 creating production image copying virtual environment and source code, setting PATH environment variable, using non-root user, and executing python -m ilograph_mcp.server command. Container features include multi-stage builds optimized for size and security, non-root user following security best practices, health checks for container monitoring integration, and label metadata providing OCI-compliant container annotations.

The deployment architecture supports client integration through JSON configuration specifying "ilograph" server using "docker" command with args ["run", "-i", "--rm", "ghcr.io/quincymillerdev/ilograph-mcp-server:latest"]. Supported clients include Claude Desktop as primary target with full feature support, VS Code integration via MCP extension, Cursor with native MCP protocol support, and custom clients using JSON-RPC over stdio/HTTP.

The quality assurance strategy implements unit tests achieving 95%+ coverage for core components, integration tests using external API mocking and real endpoint testing, performance tests conducting load testing with realistic workloads, and security tests performing vulnerability scanning and penetration testing. Continuous integration utilizes GitHub Actions for automated testing and deployment, multi-Python versions testing compatibility with Python 3.11 and 3.12, cross-platform validation on Linux, macOS, and Windows, and security scanning performing dependency vulnerability assessment.

The monitoring and observability system includes health monitoring through built-in health check endpoints, cache performance metrics, external API connectivity monitoring, and resource usage tracking. The logging strategy implements structured logging with JSON format, log levels including DEBUG, INFO, WARNING, ERROR, and CRITICAL, request/response correlation IDs, and performance timing measurements. Metrics collection tracks tool usage statistics, cache hit/miss ratios, response time distributions, and error rate monitoring.

## Future Enhancements

The planned features include advanced validation with real-time syntax highlighting integration, performance optimization suggestions, and architecture pattern detection; enhanced examples providing interactive diagram walkthroughs, custom example generation, and community-contributed examples; AI integration enabling natural language to diagram generation, automated diagram optimization, and intelligent error correction; and enterprise features supporting multi-tenant support, role-based access controls, and audit logging and compliance.

The technical roadmap for Q1 2025 includes enhanced validation with semantic analysis, performance optimization for large diagrams, and additional icon provider integrations. Q2 2025 roadmap includes real-time collaboration features, advanced caching with persistence, and integration with diagram repositories. Q3 2025 roadmap includes machine learning-powered recommendations, custom validation rule engine, and enterprise authentication integration.

The Ilograph MCP Server represents sophisticated implementation of Model Context Protocol providing AI agents comprehensive access to Ilograph's ecosystem through modular architecture, robust caching strategies, and extensive tool ecosystem enabling automated architectural documentation workflows while maintaining high performance and reliability. The project demonstrates best practices in modern Python development using async/await, type hints, and dependency management; service architecture implementing layered design, separation of concerns, and error handling; performance engineering utilizing caching, connection pooling, and resource optimization; and DevOps practices including containerization, CI/CD, monitoring, and security. This implementation serves as production-ready tool for Ilograph users and reference implementation for building sophisticated MCP servers bridging AI models with complex domain-specific systems. 